{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Load libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport glob\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\nimport torchvision\nimport pathlib\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageOps\n\nfrom torch.utils.data.dataset import Dataset\nimport torchvision.transforms as transforms\nimport cv2","metadata":{"id":"ntnOO98C7o5T","execution":{"iopub.status.busy":"2021-10-04T21:27:25.561194Z","iopub.execute_input":"2021-10-04T21:27:25.561800Z","iopub.status.idle":"2021-10-04T21:27:30.232311Z","shell.execute_reply.started":"2021-10-04T21:27:25.561718Z","shell.execute_reply":"2021-10-04T21:27:30.231580Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"KX-nGVGB8m3x","outputId":"1d80b699-32a3-4c4d-c303-01501b5cbad7","execution":{"iopub.status.busy":"2021-10-04T21:27:30.233794Z","iopub.execute_input":"2021-10-04T21:27:30.234058Z","iopub.status.idle":"2021-10-04T21:27:30.241748Z","shell.execute_reply.started":"2021-10-04T21:27:30.234026Z","shell.execute_reply":"2021-10-04T21:27:30.238647Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#checking for device\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(device)","metadata":{"id":"6Dmfdsc37o5U","outputId":"8b9d4a65-ec52-4295-f786-381cb26007dc","execution":{"iopub.status.busy":"2021-10-04T21:27:30.243357Z","iopub.execute_input":"2021-10-04T21:27:30.243711Z","iopub.status.idle":"2021-10-04T21:27:30.289787Z","shell.execute_reply.started":"2021-10-04T21:27:30.243678Z","shell.execute_reply":"2021-10-04T21:27:30.289015Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Transforms\ntransformer=transforms.Compose([\n    #transforms.RandomHorizontalFlip(),\n    transforms.Resize((256,256)),\n    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n                        [0.5,0.5,0.5]),\n    transforms.Grayscale(num_output_channels=1)\n])","metadata":{"id":"m3Tq2u727o5U","execution":{"iopub.status.busy":"2021-10-04T21:27:30.293163Z","iopub.execute_input":"2021-10-04T21:27:30.293477Z","iopub.status.idle":"2021-10-04T21:27:30.300915Z","shell.execute_reply.started":"2021-10-04T21:27:30.293453Z","shell.execute_reply":"2021-10-04T21:27:30.300224Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Dataloader\n\n#Path for training and testing directory\ntrain_path='../input/wo-other-odir-clahe-augmented/data_5/train'\nvalidation_path='../input/wo-other-odir-clahe-augmented/data_5/valid'\ntest_path='../input/wo-other-odir-clahe-augmented/data_5/test'\n\n# train_path='/content/drive/MyDrive/data_5/train'\n# validation_path='/content/drive/MyDrive/data_5/valid'\n# test_path='/content/drive/MyDrive/data_5/test'\n\n\n\ntrain_loader=DataLoader(\n    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n    batch_size=64, shuffle=True\n)\n\nvalidation_loader=DataLoader(\n    torchvision.datasets.ImageFolder(validation_path,transform=transformer),\n    batch_size=64, shuffle=True\n)\n\ntest_loader=DataLoader(\n    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n    batch_size=32, shuffle=True\n)","metadata":{"id":"VhfQHwFV7o5U","execution":{"iopub.status.busy":"2021-10-04T21:27:30.302010Z","iopub.execute_input":"2021-10-04T21:27:30.302919Z","iopub.status.idle":"2021-10-04T21:27:43.793730Z","shell.execute_reply.started":"2021-10-04T21:27:30.302794Z","shell.execute_reply":"2021-10-04T21:27:43.792947Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#CNN Network\n\n\n# class ConvNet(nn.Module):\n#     def __init__(self,num_classes):\n#         super(ConvNet,self).__init__()\n        \n#         #Output size after convolution filter\n#         #((w-f+2P)/s) +1\n        \n#         #Input shape= (256,3,150,150)\n        \n#         self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n#         #Shape= (256,12,150,150)\n#         self.bn1=nn.BatchNorm2d(num_features=12)\n#         #Shape= (256,12,150,150)\n#         self.relu1=nn.ReLU()\n#         #Shape= (256,12,150,150)\n        \n#         self.pool=nn.MaxPool2d(kernel_size=2)\n#         #Reduce the image size be factor 2\n#         #Shape= (256,12,75,75)\n        \n        \n#         self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n#         #Shape= (256,20,75,75)\n#         self.relu2=nn.ReLU()\n#         #Shape= (256,20,75,75)\n        \n        \n        \n#         self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n#         #Shape= (256,32,75,75)\n#         self.bn3=nn.BatchNorm2d(num_features=32)\n#         #Shape= (256,32,75,75)\n#         self.relu3=nn.ReLU()\n#         #Shape= (256,32,75,75)\n        \n        \n#         self.fc=nn.Linear(in_features=128 * 128 * 32,out_features=num_classes)\n        \n        \n        \n#         #Feed forwad function\n        \n#     def forward(self,input):\n#         output=self.conv1(input)\n#         output=self.bn1(output)\n#         output=self.relu1(output)\n            \n#         output=self.pool(output)\n            \n#         output=self.conv2(output)\n#         output=self.relu2(output)\n            \n#         output=self.conv3(output)\n#         output=self.bn3(output)\n#         output=self.relu3(output)\n            \n            \n#             #Above output will be in matrix form, with shape (256,32,75,75)\n            \n#         output=output.view(-1,32*128*128)\n            \n            \n#         output=self.fc(output)\n            \n#         return output","metadata":{"id":"QODucQad7o5V","outputId":"c70d414b-34b6-4b4b-f37e-3e973e99eae4","execution":{"iopub.status.busy":"2021-10-04T21:27:43.798267Z","iopub.execute_input":"2021-10-04T21:27:43.800344Z","iopub.status.idle":"2021-10-04T21:27:43.808755Z","shell.execute_reply.started":"2021-10-04T21:27:43.800302Z","shell.execute_reply":"2021-10-04T21:27:43.807957Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#CNN Network modified\n\n\nclass ConvNet(nn.Module):\n    def __init__(self,num_classes):\n        super(ConvNet,self).__init__()\n        \n        #Output size after convolution filter\n        #((w-f+2P)/s) +1\n        \n        #Input shape= (256,3,150,150)\n        \n        self.conv1=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,12,150,150)\n        self.bn1=nn.BatchNorm2d(num_features=32)\n        #Shape= (256,12,150,150)\n        self.relu1=nn.Softmax(dim=1)\n        #Shape= (256,12,150,150)\n\n        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2)\n         \n        #Reduce the image size be factor 2\n        #Shape= (256,12,75,75)\n        \n        \n        self.conv2=nn.Conv2d(in_channels=32,out_channels=128,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,20,75,75)\n        self.bn2=nn.BatchNorm2d(num_features=128)\n        self.relu2=nn.Softmax(dim=1)\n        self.pool2=nn.MaxPool2d(kernel_size=2,stride=2)\n        #Shape= (256,20,75,75)\n        \n        \n        \n        # self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n        # #Shape= (256,32,75,75)\n        # self.bn3=nn.BatchNorm2d(num_features=32)\n        # #Shape= (256,32,75,75)\n        # self.relu3=nn.Softmax(dim=1)\n        # #Shape= (256,32,75,75)\n\n       \n        \n        \n        self.fc=nn.Linear(in_features=128* 64 * 64,out_features=128)\n        self.fc2=nn.Linear(128,out_features=num_classes)\n        \n        \n        \n        #Feed forwad function\n        \n    def forward(self,input):\n        output=self.conv1(input)\n        output=self.bn1(output)\n        output=self.relu1(output)\n        output=self.pool1(output)\n\n            \n        output=self.conv2(output)\n        output=self.bn2(output)\n        output=self.relu2(output)\n        output=self.pool2(output)\n            \n        # output=self.conv3(output)\n        # output=self.bn3(output)\n        # output=self.relu3(output)\n       \n            \n            \n            #Above output will be in matrix form, with shape (256,32,75,75)\n            \n        output=output.view(-1,128*64*64)\n            \n            \n        output=self.fc(output)\n        output=self.fc2(output)\n            \n        return output\n","metadata":{"id":"dOyYpcPl_Myf","execution":{"iopub.status.busy":"2021-10-04T21:27:43.812984Z","iopub.execute_input":"2021-10-04T21:27:43.815729Z","iopub.status.idle":"2021-10-04T21:27:43.833876Z","shell.execute_reply.started":"2021-10-04T21:27:43.815690Z","shell.execute_reply":"2021-10-04T21:27:43.833275Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model=ConvNet(num_classes=4).to(device)\n\n\n#Optmizer and loss function\noptimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\nloss_function=nn.CrossEntropyLoss()\n\nnum_epochs=5\n\n# calculating the size of training and testing images\ntrain_count=len(glob.glob(train_path+'/**/*.jpg'))\ntest_count=len(glob.glob(test_path+'/**/*.jpg'))\nvalidation_count=len(glob.glob(validation_path+'/**/*.jpg'))\n\nprint(train_count,test_count,validation_count)","metadata":{"id":"Go1envS97o5W","outputId":"dddc598d-f285-4959-f8db-8d97a32ca9f8","execution":{"iopub.status.busy":"2021-10-04T21:27:43.838495Z","iopub.execute_input":"2021-10-04T21:27:43.840868Z","iopub.status.idle":"2021-10-04T21:27:49.858264Z","shell.execute_reply.started":"2021-10-04T21:27:43.840830Z","shell.execute_reply":"2021-10-04T21:27:49.856983Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Model training and saving best model\n\niter = []\ntrain_losses = []\nvalid_losses = []\nitr = 0\ntotal_step = len(train_loader)\n\nbest_accuracy=0.0\n\nfor epoch in range(num_epochs):\n    \n    #Evaluation and training on training dataset\n    model.train()\n    train_accuracy=0.0\n    train_loss=0.0\n    \n    for i, (images,labels) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        optimizer.zero_grad()\n        \n        outputs=model(images)\n        loss=loss_function(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        \n        itr = itr + 1\n        if (i+1) % 20 == 0:\n            iter.append(itr)\n            train_losses.append(loss.item())\n            print ('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}'\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n        \n        \n        train_loss+= loss.cpu().data*images.size(0)\n        _,prediction=torch.max(outputs.data,1)\n        \n        train_accuracy+=int(torch.sum(prediction==labels.data))\n        \n    train_accuracy=train_accuracy/train_count\n    train_loss=train_loss/train_count\n\n\n    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n\n\n\n    \n    \n    \n    model.eval()\n    validation_accuracy=0.0\n    validation_loss=0.0\n    \n    total_step = len(validation_loader)\n    \n    for i, (images,labels) in enumerate(validation_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n        \n        outputs=model(images)\n        loss=loss_function(outputs,labels)\n        \n#         itr = itr + 1\n        if (i+1) % 20 == 0:\n            iter.append(itr)\n            valid_losses.append(loss.item())\n            print ('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}'\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n        \n        validation_loss+= loss.cpu().data*images.size(0)\n        _,prediction=torch.max(outputs.data,1)\n        \n        validation_accuracy+=int(torch.sum(prediction==labels.data))\n        \n    validation_accuracy=validation_accuracy/validation_count\n    validation_loss=validation_loss/validation_count\n\n    print('Epoch: '+str(epoch)+' Validation Loss: '+str(validation_loss)+' Validation Accuracy: '+str(validation_accuracy))","metadata":{"id":"rkSmofa1fgAL","execution":{"iopub.status.busy":"2021-10-04T21:27:49.859716Z","iopub.execute_input":"2021-10-04T21:27:49.859985Z","iopub.status.idle":"2021-10-04T21:36:48.271455Z","shell.execute_reply.started":"2021-10-04T21:27:49.859951Z","shell.execute_reply":"2021-10-04T21:36:48.270607Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"y_pred = []\ny_test = []\n\n# Evaluation on testing dataset\nmodel.eval()\n\n\ntest_accuracy=0.0\n\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for i, (images,labels) in enumerate(test_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n\n        outputs=model(images)\n        _,prediction=torch.max(outputs.data,1)\n        test_accuracy+=int(torch.sum(prediction==labels.data))\n        \n        total += labels.size(0)\n        correct += (prediction == labels).sum().item()\n\n        y_pred.extend(prediction)\n        y_test.extend(labels)\n\ntest_accuracy=test_accuracy/test_count\n\n\nprint('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n\n\n#Save the best model\nif test_accuracy>best_accuracy:\n    torch.save(model.state_dict(),'./best_checkpoint.model')\n    best_accuracy=test_accuracy","metadata":{"id":"QUqAQAR77o5X","execution":{"iopub.status.busy":"2021-10-04T21:36:48.273762Z","iopub.execute_input":"2021-10-04T21:36:48.274266Z","iopub.status.idle":"2021-10-04T21:37:04.732960Z","shell.execute_reply.started":"2021-10-04T21:36:48.274228Z","shell.execute_reply":"2021-10-04T21:37:04.732054Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plt.plot(iter[ : 30], train_losses, label='Loss')\nplt.title('Loss Curve')\nplt.ylabel('Loss')\nplt.xlabel('Iteration')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:37:39.768755Z","iopub.execute_input":"2021-10-04T21:37:39.769565Z","iopub.status.idle":"2021-10-04T21:37:39.994684Z","shell.execute_reply.started":"2021-10-04T21:37:39.769516Z","shell.execute_reply":"2021-10-04T21:37:39.994033Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"yy_test = []\n\nfor i in range(len(y_test)):\n    yy_test.append(int(y_test[i]))\n\nprint(yy_test)\n\nyy_pred = []\n\nfor i in range(len(y_pred)):\n    yy_pred.append(int(y_pred[i]))\n\nprint(yy_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:37:45.806844Z","iopub.execute_input":"2021-10-04T21:37:45.807146Z","iopub.status.idle":"2021-10-04T21:37:45.853246Z","shell.execute_reply.started":"2021-10-04T21:37:45.807117Z","shell.execute_reply":"2021-10-04T21:37:45.852591Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\nimport seaborn as sns\n\ndef show_confusion_matrix(confusion_matrix):\n    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=0, ha='center')\n    plt.ylabel('True Labels')\n    plt.xlabel('Predicted Labels');\ncm = confusion_matrix(yy_test, yy_pred)\ndf_cm = pd.DataFrame(cm, index=['AMD', 'Cataract', 'Myopia', 'Normal'], columns=['AMD', 'Cataract', 'Myopia', 'Normal'])\nshow_confusion_matrix(df_cm)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:37:47.459499Z","iopub.execute_input":"2021-10-04T21:37:47.460284Z","iopub.status.idle":"2021-10-04T21:37:48.690580Z","shell.execute_reply.started":"2021-10-04T21:37:47.460237Z","shell.execute_reply":"2021-10-04T21:37:48.689900Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print('F1 score: ', f1_score(yy_test, yy_pred, average='weighted'))\nprint('Precision: ', precision_score(yy_test, yy_pred, average='weighted'))\nprint('Recall: ', recall_score(yy_test, yy_pred, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:40:54.262841Z","iopub.execute_input":"2021-10-04T21:40:54.263408Z","iopub.status.idle":"2021-10-04T21:40:54.288227Z","shell.execute_reply.started":"2021-10-04T21:40:54.263371Z","shell.execute_reply":"2021-10-04T21:40:54.287457Z"},"trusted":true},"execution_count":24,"outputs":[]}]}